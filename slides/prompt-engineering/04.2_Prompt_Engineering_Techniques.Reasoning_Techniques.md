---
title: "Prompt Engineering Techniques"
module: "01 - Prompt Engineering"
order: 4
tags:
  - prompts
  - sdk
duration: "30min"
marp: true
theme: default
paginate: true
doc-type: content

header: Introduction to Prompt Engineering
footer: "© Microsoft Corporation. All rights reserved."
style: |
  @import '../styles/msft.css';

  section {
    overflow-y: scroll;
  }

---

<!-- _class: 'title-slide' -->
<!-- _paginate: skip -->

# Prompt Engineering Techniques

## Reasoning Techniques

---

### Reasoning Frameworks / Cognitive Architectures

---

#### Chain-of-Thought (CoT) Reasoning
CoT prompting guides LLMs to generate intermediate reasoning steps, improving their accuracy on complex problems (especially mathematics and stepwise logic). It works with general LLMs, does not require fine-tuning, and builds interpretability into outputs.

**Example:**
Prompt: When I was 3 years old, my partner was 3 times my age. Now, I am 20 years old. How old is my partner? Let's think step by step.

Output:
1. When I was 3, my partner was 3 * 3 = 9 years old.
2. The age gap is 6 years.
3. Now I am 20, so my partner is 20 + 6 = 26 years old.
**Answer:** 26

CoT can be used in zero-shot and few-shot settings; combining with examples can dramatically improve output reliability.

**Use cases:** code generation, problem decomposition, synthetic data creation, or any scenario where "thinking aloud" through the answer is helpful.

---

#### Tree-of-Thought (ToT)
Extends CoT by enabling the model to branch reasoning and explore multiple possibilities at each step, using a tree structure. ToT is ideal for complex problem-solving where backtracking and comparing alternatives are valuable. Each branch (or "thought") is a coherent reasoning step; models can traverse different branches, evaluate intermediate results, and choose the best solution path.

**Example:**

**Use cases:**
- Complex problem-solving (e.g., puzzles, planning, creative writing)
- Scenarios requiring exploration of alternatives and backtracking
- Tasks where evaluating and comparing multiple reasoning paths is beneficial

---

#### Graph-of-Thought (GoT)
GoT represents reasoning as a flexible graph, not just a tree or chain. Thoughts (nodes) can connect in non-linear ways, allowing for iterative refinement and multi-directional reasoning. This mirrors complex human thought processes and is useful for tasks with interdependent subproblems.

**Example:**
Suppose the problem is: "How do you solve the problem of climate change?"

Instead of following a single, linear chain of reasoning, GoT breaks the problem into interconnected sub-questions (nodes), each exploring a different aspect. For example:

* Node 1: What are the economic impacts of climate change?
Explores: Effects on the global and U.S. economy, costs of inaction, etc.
* Node 2: How does renewable energy help mitigate climate change?
Explores: Impact of renewables, global adoption, personal stories, etc.
* Node 3: What are policy solutions for climate change?
Explores: Carbon taxes, international agreements, local initiatives, etc.

Each node can connect to others (e.g., economic impacts link to policy solutions), and the reasoning can move back and forth between them, revisiting and refining ideas as new insights emerge. This structure allows for multi-directional, iterative reasoning—mirroring how humans tackle complex, interdependent problems.

**Use cases:**
- Multi-modal reasoning (combining text, images, data)
- Problems with interdependent steps or feedback loops
- Iterative tasks where revisiting and refining earlier steps is needed

---

#### Sketch-of-Thought (SoT)
SoT uses expert lexicons and chunked symbolism as short-hand expressions to constrain reasoning about a specific domain and reduce token usage.

**Example:**
For a logic puzzle, instead of writing "If A is true, then B must be false," SoT might use: "A→¬B".

**Use cases:**
- Commonsense reasoning and multi-hop inference
- Fact-based recall tasks
- Scenarios requiring concise, structured, and efficient reasoning

---

#### Active Prompts & ReasonFlux
Active Prompts dynamically adapt prompt content or structure in response to model outputs or user interaction, creating an iterative feedback loop for enhanced problem solving.

ReasonFlux refers to managing and refining flows of reasoning across multiple cycles, often with feedback-driven improvement at each stage.

**Example:**
In customer support, the model asks clarifying questions based on user responses, refining its answers iteratively. In data analysis, prompts are adjusted based on previous outputs to drill down into insights.

**Use cases:**
- Interactive applications (customer support, tutoring)
- Data analysis and reporting
- Any scenario where iterative refinement and feedback improve results

---

#### ReAct (Reason & Act)
Blends logical reasoning with tool use (e.g. searching the web, running code). The LLM alternates between “thinking” (reasoning) and “acting” (calling an external tool), updating internal state with results at every iteration.


**Example:**
Suppose the question is:
"How many rooms are in the hotel that is home to the Cirque du Soleil show Mystere?"

The ReAct process would look like this:

Thought: I need to find out which hotel hosts the Cirque du Soleil show Mystere.
Action: Search for "hotel hosting Cirque du Soleil Mystere".
Observation: The show Mystere is hosted at Treasure Island Hotel.
Thought: Now, I need to find out how many rooms are in Treasure Island Hotel.
Action: Search for "number of rooms in Treasure Island Hotel".
Observation: Treasure Island Hotel has 2,884 rooms.
Thought: I now know the final answer.
Final Answer: Treasure Island Hotel, which hosts Mystere, has 2,884 rooms.

**Use cases:**
- Complex question answering requiring external information
- Web search and fact-checking tasks
- Data extraction and aggregation from multiple sources
- Tool-augmented reasoning (e.g., calculators, APIs)
- Interactive agents (assistants, chatbots) that need to reason and act iteratively
- Any scenario where combining logical reasoning with real-time actions improves accuracy or utility

---

#### Prompt Chaining

**Definition:** Connecting several prompts so the output of one becomes the input to the next. This enables complex, multi-step workflows in which each prompt handles a distinct sub-task.

**Concrete Uses:**
- Decomposing a challenging question into simpler parts, with separate prompts for each step.
- Popular with tasks like legal document analysis, multi-part data extraction, and multi-stage conversation agents.

**Advantages:** Increases modularity, allows for iterative refinement, and makes error diagnosis easier by identifying failing steps within a chain.

---

#### Self-Consistency

**Definition:** Improves reliability by running a prompt multiple times (using a high temperature for diversity) and then aggregating answers; the most frequent (self-consistent) result is chosen.

**Steps:**
1. Generate multiple outputs using the same prompt (encourage reasoning diversity).
2. Extract answers from each.
3. Vote/aggregate to choose the most common answer.

**Example:** Classify an ambiguous email repeatedly; if the majority of runs say "IMPORTANT", that label is returned.

**Use cases:**
- Ambiguous classification tasks
- Complex reasoning where multiple paths lead to correct answers
- Improving reliability without fine-tuning

---

#### Reflexion

**Definition:** Prompt the model to critique or revise its own output, iteratively. Often involves metaprompts that ask for error checking, self-assessment, or explicit correction strategies.

**Example:**
1. Generate initial response
2. Ask model: "Review your response for errors and provide corrections"
3. Generate refined response based on self-critique

**Use cases:**
- Code generation and review
- Content quality improvement
- Complex problem-solving requiring verification