---
title: "Prompt Engineering Techniques"
module: "01 - Prompt Engineering"
order: 4
tags:
  - prompts
  - sdk
duration: "30min"
marp: true
theme: default
paginate: true
doc-type: content

header: Introduction to Prompt Engineering
footer: "Â© Microsoft Corporation. All rights reserved."
style: |
  @import '../styles/msft.css';

  section {
    overflow-y: scroll;
  }

---

<!-- _class: 'title-slide' -->
<!-- _paginate: skip -->

# Prompt Engineering Techniques

## Constrained Decoding

Imposes syntactic, semantic, or business-rules constraints on output (e.g., requiring a valid JSON schema, restricting vocabulary, etc.) Useful for compliance, safety, and ensuring model responses can be programmatically parsed and trusted. Effective prompts balance clear instructions (what to do) and explicit constraints (what not to do).

---

### Grounding

Grounding refers to ensuring that model outputs are based on verifiable facts or external data, rather than just the model's internal knowledge. This is crucial for applications requiring high factual accuracy.

**Use Cases:**
- Fact-checking and verification tasks
- Preventing hallucinations in knowledge-dependent domains
- Legal and compliance documentation
- Medical and scientific applications
- Real-time data integration

**Example:**
```typescript
const prompt = `Based ONLY on the following provided documents, 
answer the user's question. If the answer cannot be found in the 
provided context, respond with "I cannot find this information."

[PROVIDED DOCUMENTS]
${documentContext}

User Question: ${userQuestion}`;
```

**Key Benefits:**
- Reduces hallucinations and false information
- Improves trustworthiness and reliability
- Enables auditable decision-making
- Ensures compliance with data sources
- Supports fact-based reasoning

**Best Practices:**
- Always provide reference materials explicitly
- Use phrases like "Based on the provided context"
- Include source citations in outputs
- Validate outputs against grounding sources
- Combine with retrieval-augmented generation (RAG)

**Limitations:**
- Requires high-quality source material
- Can limit model creativity and synthesis
- Increases prompt length and latency
- May miss valid inferences outside provided context

---

### Logit Biasing

Logit biasing allows you to influence token probabilities during generation by increasing or decreasing the likelihood of specific tokens appearing in the output. This provides fine-grained control over model behavior without modifying the prompt itself.

**Use Cases:**
- Enforce specific output formats or keywords
- Prevent unwanted tokens or phrases
- Guide the model toward preferred terminology
- Ensure compliance with safety policies
- Improve consistency in structured outputs

**Example:**
```json
{
  "model": "gpt-4",
  "logit_bias": {
    "91": 100,      // Strongly encourage ']' token
    "4296": -100,   // Strongly discourage 'toxic' token
    "25039": 50     // Moderately encourage 'helpful' token
  }
}
```

**Key Benefits:**
- Deterministic control over specific tokens
- Lighter-weight than prompt engineering alone
- Works alongside other constraint techniques
- Reduces hallucinations and unwanted outputs
- Enables domain-specific vocabulary enforcement

**Limitations:**
- Requires token IDs specific to the model's vocabulary
- Can impact generation quality if overused
- Not available in all models or APIs
- Best combined with clear prompting for optimal results

---

### Structured Output

Design prompts to elicit responses in predefined, machine-readable formats (such as JSON, XML, tables). Vital for integration with downstream applications or automated data pipelines.

**Use Cases:**
- API response standardization
- Data extraction and transformation
- Form filling and automation
- Report generation with consistent structure
- System integration and interoperability

**Example:**
```typescript
const prompt = `Extract the following information from the text 
and return as JSON:

{
  "name": string,
  "email": string,
  "phone": string,
  "address": {
    "street": string,
    "city": string,
    "state": string,
    "zip": string
  }
}

Text to extract from:
${inputText}`;
```

**Key Benefits:**
- Enables programmatic processing of responses
- Reduces parsing errors and ambiguity
- Improves integration with downstream systems
- Facilitates data pipeline automation
- Simplifies validation and error checking

**Best Practices:**
- Provide explicit schema or format examples
- Include sample outputs showing expected structure
- Use consistent naming conventions
- Add field-level descriptions
- Specify required vs. optional fields
- Use validation to catch malformed responses

**Limitations:**
- May constrain model creativity
- Large schemas can increase token usage
- Requires post-processing validation
- Some models handle structured output better than others
